{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='blue'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='green'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='green'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='green'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='blue' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0 = 0.0001, alpha = 0.0001, loss = 'log', random_state = 15, penalty = 'l2', \n",
    "                                 tol = 1e-3, verbose = 2, learning_rate = 'constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.22 seconds.\n",
      "Convergence after 14 epochs took 0.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X = X_train, y = y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " (1, 15),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='blue' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Initialize weights </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = X_train[0] \n",
    "w, b = initialize_weights(dim)\n",
    "print('w =', (w))\n",
    "print('b =', str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Grader function - 1 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = X_train[0] \n",
    "w, b = initialize_weights(dim)\n",
    "def grader_weights(w, b):\n",
    "    assert((len(w) == len(dim)) and b == 0 and np.sum(w) == 0.0)\n",
    "    return True\n",
    "grader_weights(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Compute sigmoid </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    value = 1 / (1 + np.exp(-z))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Grader function - 2</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    val = sigmoid(z)\n",
    "    assert(val == 0.8807970779778823)\n",
    "    return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='MediumVioletRed'><b> Compute loss</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    loss = 0.0\n",
    "    for i in range(len(y_true)):\n",
    "        loss += (y_true[i] * np.log10(y_pred[i] + 0.000000000000000000000001)) + ((1 - y_true[i]) * np.log10(1 - y_pred[i] + 0.000000000000000000000001))\n",
    "    return -loss/float(len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Grader function - 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss = logloss(true,pred)\n",
    "    assert(loss == 0.07644900402910389)\n",
    "    return True\n",
    "true = [1, 1, 0, 1, 0]\n",
    "pred = [0.9, 0.8, 0.1, 0.8, 0.2]\n",
    "grader_logloss(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Compute gradient w.r.t.  'w' </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x, y, w, b, alpha, N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    sigma = sigmoid(np.dot(w.T, x) + b)\n",
    "    dw = x * (y - sigma) - (alpha * w) / N\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Grader function - 4 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x, y, w, b, alpha, N):\n",
    "    grad_dw = gradient_dw(x, y, w, b, alpha, N)\n",
    "    assert(np.sum(grad_dw) == 2.613689585)\n",
    "    return True\n",
    "grad_x = np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y = 0\n",
    "grad_w, grad_b = initialize_weights(grad_x)\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "grader_dw(grad_x, grad_y, grad_w, grad_b, alpha, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Compute gradient w.r.t. 'b'</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_db(x, y, w, b):\n",
    "    '''In this fuction, we will compute gradienct w.r.t b '''\n",
    "    db = y - sigmoid(np.dot(w.T, x) + b)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Grader function - 5 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x, y, w, b):\n",
    "    grad_db = gradient_db(x, y, w, b)\n",
    "    assert(grad_db == -0.5)\n",
    "    return True\n",
    "grad_x = np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y = 0\n",
    "grad_w, grad_b = initialize_weights(grad_x)\n",
    "alpha = 0.0001\n",
    "N = len(X_train)\n",
    "grader_db(grad_x, grad_y, grad_w, grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='MediumVioletRed'> <b>Implementing logistic regression</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z = np.dot(w, X[i]) + b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, epochs, alpha, eta0):\n",
    "    \n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    # Here eta0 is learning rate\n",
    "    # implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    # for every epoch\n",
    "        # for every data point(X_train,y_train)\n",
    "           # compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           # compute gradient w.r.to b (call the gradient_db() function)\n",
    "           # update w, b\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        # compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the train loss values in a list\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        # compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the test loss values in a list\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "    log_loss_train = []\n",
    "    log_loss_test = []\n",
    "    \n",
    "    N = len(X_train)\n",
    "    w, b = initialize_weights(X_train[0])\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        for i, j in zip(X_train, y_train):\n",
    "            grad_w = gradient_dw(i, j, w, b, alpha, N)\n",
    "            grad_b = gradient_db(i, j, w, b)\n",
    "            w += (eta0 * grad_w)\n",
    "            b += (eta0 * grad_b)\n",
    "        \n",
    "        y_pred_train = pred(w, b, X_train)\n",
    "        train_log_loss = logloss(y_train, y_pred_train)\n",
    "        log_loss_train.append(train_log_loss)\n",
    "        #print(\"Train log loss: \", train_log_loss)\n",
    "        y_pred_test = pred(w, b, X_test)\n",
    "        test_log_loss = logloss(y_test, y_pred_test)\n",
    "        log_loss_test.append(test_log_loss)\n",
    "        \n",
    "        #print(\"Test log loss: \", test_log_loss) \n",
    "    return w, b, log_loss_train, log_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9048262   0.64656179 -0.07822054  0.63777662 -0.3907577   0.9442469\n",
      " -0.90299306 -0.07160359  0.41570122  0.42360749  0.25179668  0.05395901\n",
      " -0.08823163  0.54374451  0.06700376] -1.3119223645129903\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "eta0 = 0.0001\n",
    "N = len(X_train)\n",
    "epochs = 15\n",
    "        \n",
    "w,b,log_loss_train,log_loss_test = train(X_train, y_train, X_test, y_test, epochs, alpha, eta0)\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='MediumVioletRed'><b><u>Goal of assignment</u></b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01475437,  0.01493816, -0.00227909,  0.00670554, -0.00641395,\n",
       "          0.01189447, -0.00725785,  0.00180162,  0.00978705,  0.00360839,\n",
       "          0.00457525,  0.00349702,  0.00054823,  0.00292799,  0.00056488]]),\n",
       " array([-0.00611698]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented SGD and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='MediumVioletRed'><b>Plot epoch number vs train, test loss </b></font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(0,15)\n",
    "plt.plot(epochs, log_loss_train , 'g', label='Train Log loss')\n",
    "plt.plot(epochs, log_loss_test , 'b', label='Test Log loss') \n",
    "plt.xlabel('epoch', fontsize = 15)\n",
    "plt.ylabel('loss', fontsize = 15)\n",
    "plt.title('Epoch v/s Logistic log loss', fontname =\"Brush Script MT\", fontsize = 28, pad = 30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-k28U1xDsLIO"
   },
   "source": [
    "<font color = 'MediumVioletRed'><h4><i><u>Conclusion</u></i></h4>\n",
    "After epoch 10 the Train and the Test log loss is almost constant.\n",
    "<br>\n",
    "Train log loss is significantly more than the Test log loss.</p></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9506666666666667\n",
      "0.94768\n"
     ]
    }
   ],
   "source": [
    "def pred(w, b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z = np.dot(w, X[i]) + b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1 - np.sum(y_train - pred(w, b, X_train)) / len(X_train))\n",
    "print(1 - np.sum(y_test  - pred(w, b, X_test)) / len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
